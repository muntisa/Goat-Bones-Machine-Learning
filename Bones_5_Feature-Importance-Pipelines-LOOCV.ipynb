{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection for Goat Bones project\n",
    "\n",
    "We used pipelines for classifiers with LOOCV.\n",
    "\n",
    "For each dataset, classifier and folds:\n",
    "- Robust scaling\n",
    "- LOOCV\n",
    "- balanced accurary as score\n",
    "\n",
    "We will use folders *datasets2* for the best classifiers:\n",
    "\n",
    "| Output | Classifier | Features          | Best AUC |\n",
    "|--------|------------|-------------------|----------|\n",
    "| Fw     | SVM        | MAi, MAmix, Metab | 0.911    |\n",
    "| Fl     | SVM linear | MAmix             | 0.875    |\n",
    "| Fd     | SVM        | MAmix, Metab      | 0.893    |\n",
    "| Hw     | SVM linear | MAmix             | 0.750    |\n",
    "| Hl     | SVM        | MAmix             | 0.696    |\n",
    "| Hd     | SVM        | MAmix, Metab      | 0.857    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, StratifiedKFold, LeaveOneOut\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, roc_auc_score,f1_score, recall_score, precision_score\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LassoCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.feature_selection import RFECV, VarianceThreshold, SelectKBest, chi2\n",
    "from sklearn.feature_selection import SelectFromModel, SelectPercentile, f_classif\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ./datasets2/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ./results2_LOOCV/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define script parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a label for output files\n",
    "targetName = '_FeatImp_'\n",
    "foldTypes = [56]\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  set_weights(y_data, option='balanced'):\n",
    "    \"\"\"Estimate class weights for umbalanced dataset\n",
    "       If ‘balanced’, class weights will be given by n_samples / (n_classes * np.bincount(y)). \n",
    "       If a dictionary is given, keys are classes and values are corresponding class weights. \n",
    "       If None is given, the class weights will be uniform \"\"\"\n",
    "    cw = class_weight.compute_class_weight(option, np.unique(y_data), y_data)\n",
    "    w = {i:j for i,j in zip(np.unique(y_data), cw)}\n",
    "    return w "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataFromDataset(sFile, OutVar):\n",
    "    # read details file\n",
    "    print('\\n-> Read dataset', sFile)\n",
    "    df = pd.read_csv(sFile)\n",
    "    #df = feather.read_dataframe(sFile)\n",
    "    print('Shape', df.shape)\n",
    "    # print(list(df.columns))\n",
    "    \n",
    "    # select X and Y\n",
    "    ds_y = df[OutVar]\n",
    "    ds_X = df.drop(OutVar,axis = 1)\n",
    "    Xdata = ds_X.values # get values of features\n",
    "    Ydata = ds_y.values # get output values\n",
    "\n",
    "    print('Shape X data:', Xdata.shape)\n",
    "    print('Shape Y data:',Ydata.shape)\n",
    "    \n",
    "    # return data for X and Y, feature names as list\n",
    "    return (Xdata, Ydata, list(ds_X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to calculate ACC with LOOCV pipelines\n",
    "\n",
    "def getACC(y, yhat):\n",
    "    good = 0 # number of cases where y = yhat = good prediction\n",
    "    \n",
    "    for i in range(len(yhat)):\n",
    "        if yhat[i] == y[i]: good +=1\n",
    "            \n",
    "    return float(good/len(yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pipeline_OuterCV(Xdata, Ydata, label = 'my', class_weights = {0: 1, 1: 1}, folds = 3, seed = 42):\n",
    "    # inputs:\n",
    "    # data for X, Y; a label about data, number of folds, seeed\n",
    "    # default: 3-fold CV, 1:1 class weights (ballanced dataset)\n",
    "    \n",
    "    # define classifiers\n",
    "    names = ['SVM']\n",
    "    classifiers = [SVC(kernel = 'rbf', random_state=seed,gamma='auto')]\n",
    "    \n",
    "                   # results dataframe: each column for a classifier\n",
    "    df_res = pd.DataFrame(columns=names)\n",
    "\n",
    "    # build each classifier\n",
    "    print('* Building scaling+feature selection+outer '+str(folds)+'-fold CV for '+str(len(names))+' classifiers:', str(names))\n",
    "    total = time.time()\n",
    "    \n",
    "    # define a fold-CV for all the classifier\n",
    "    outer_cv = LeaveOneOut()\n",
    "    \n",
    "    resML = [] # list with ML results\n",
    "    \n",
    "    # for each classifier\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        start = time.time()\n",
    "        \n",
    "        # create pipeline: scaler + classifier\n",
    "        estimators = []\n",
    "        \n",
    "        # SCALER\n",
    "        estimators.append(('Scaler', RobustScaler() ))\n",
    "        \n",
    "        # add Classifier\n",
    "        estimators.append(('Classifier', clf)) \n",
    "        \n",
    "        # create pipeline\n",
    "        model = Pipeline(estimators)\n",
    "        \n",
    "        # evaluate pipeline\n",
    "        scores = cross_val_score(model, Xdata, Ydata, cv=outer_cv, scoring='balanced_accuracy', n_jobs=-1)\n",
    "        ACC = getACC(list(Ydata), list(scores))\n",
    "        resML.append(ACC)\n",
    "        print('%s, ACC=%0.2f, Time:%0.1f mins' % (name, ACC, (time.time() - start)/60))\n",
    "        \n",
    "    print('Total time:', (time.time() - total)/60, ' mins')             \n",
    "    \n",
    "    # return a list of lists for each classifier\n",
    "    return resML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance by removoal for SVM RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each subset file\n",
    "all_results =[ ] # all results \n",
    "outVars = ['Fw_Class_MAi_MAmix_Metab',\n",
    "           'Fd_Class_MAmix_Metab',\n",
    "           'Hl_Class_MAmix',\n",
    "           'Hd_Class_MAmix_Metab']\n",
    "\n",
    "OrigAUC = [0.911, 0.893, 0.696, 0.857]\n",
    "k=0\n",
    "for OutVar in outVars:\n",
    "    sFile = './datasets2/ds.'+str(OutVar)+'.csv'\n",
    "\n",
    "    # get data from file\n",
    "    Xdata, Ydata, Features = getDataFromDataset(sFile,OutVar)\n",
    "    \n",
    "    # Feature importance by elimination (eliminate each feature and see score diff)\n",
    "    for i in range(len(Features)):\n",
    "        Xdata_new = np.delete(Xdata, i,1)\n",
    "\n",
    "        # Calculate class weights\n",
    "        class_weights = set_weights(Ydata)\n",
    "        print(\"Class weights = \", class_weights)\n",
    "\n",
    "        # try different folds for each subset -> box plots\n",
    "        for folds in foldTypes:\n",
    "\n",
    "            # calculate outer CV for different binary classifiers\n",
    "            resList=[]\n",
    "            myACC = Pipeline_OuterCV(Xdata_new, Ydata, label = OutVar, class_weights = class_weights, folds = folds, seed = seed)\n",
    "            print(myACC)\n",
    "            resList.append(float(myACC[0]))\n",
    "            resList.append(float(myACC[0])-OrigAUC[k]) # add feature name to ACC\n",
    "            resList.append(Features[i]) # add feature name to ACC\n",
    "            resList.append(OutVar) # add file tag\n",
    "        \n",
    "        \n",
    "        # add each result to a summary dataframe\n",
    "        all_results.append(resList)\n",
    "    k=k+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the results ordered by Dataset and Difference between the new AUC without a feature and the ACC for all features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(all_results,columns=['New ACC', 'Diff with Pool ACC', 'Removed Feature', 'Dataset'])\n",
    "df_results.sort_values(by=['Dataset','Diff with Pool ACC'], inplace=True)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resFile = './results2_LOOCV/'+'FeatImpbyRemoval-LOOCV_SVM_ACC.csv'\n",
    "df_results.to_csv(resFile, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance by removal for SVM linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pipeline_OuterCV2(Xdata, Ydata, label = 'my', class_weights = {0: 1, 1: 1}, folds = 3, seed = 42):\n",
    "    # inputs:\n",
    "    # data for X, Y; a label about data, number of folds, seeed\n",
    "    # default: 3-fold CV, 1:1 class weights (ballanced dataset)\n",
    "    \n",
    "    # define classifiers\n",
    "    names = ['SVM linear']\n",
    "    classifiers = [SVC(kernel=\"linear\",random_state=seed,gamma='scale')]\n",
    "    \n",
    "                   # results dataframe: each column for a classifier\n",
    "    df_res = pd.DataFrame(columns=names)\n",
    "\n",
    "    # build each classifier\n",
    "    print('* Building scaling+feature selection+outer '+str(folds)+'-fold CV for '+str(len(names))+' classifiers:', str(names))\n",
    "    total = time.time()\n",
    "    \n",
    "    # define a fold-CV for all the classifier\n",
    "    outer_cv = LeaveOneOut()\n",
    "    \n",
    "    resML = [] # list with ML results\n",
    "    \n",
    "    # for each classifier\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        start = time.time()\n",
    "        \n",
    "        # create pipeline: scaler + classifier\n",
    "        estimators = []\n",
    "        \n",
    "        # SCALER\n",
    "        estimators.append(('Scaler', RobustScaler() ))\n",
    "        \n",
    "        # add Classifier\n",
    "        estimators.append(('Classifier', clf)) \n",
    "        \n",
    "        # create pipeline\n",
    "        model = Pipeline(estimators)\n",
    "        \n",
    "        # evaluate pipeline\n",
    "        scores = cross_val_score(model, Xdata, Ydata, cv=outer_cv, scoring='balanced_accuracy', n_jobs=-1)\n",
    "        ACC = getACC(list(Ydata), list(scores))\n",
    "        resML.append(ACC)\n",
    "        print('%s, ACC=%0.2f, Time:%0.1f mins' % (name, ACC, (time.time() - start)/60))\n",
    "        \n",
    "    print('Total time:', (time.time() - total)/60, ' mins')             \n",
    "    \n",
    "    # return a list of lists for each classifier\n",
    "    return resML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each subset file\n",
    "all_results =[ ] # all results \n",
    "outVars = ['Fl_Class_MAmix','Hw_Class_MAmix']\n",
    "OrigAUC = [0.875, 0.750]\n",
    "k=0\n",
    "\n",
    "for OutVar in outVars:\n",
    "    sFile = './datasets2/ds.'+str(OutVar)+'.csv'\n",
    "\n",
    "    # get data from file\n",
    "    Xdata, Ydata, Features = getDataFromDataset(sFile,OutVar)\n",
    "    \n",
    "    # Feature importance by elimination (eliminate each feature and see score diff)\n",
    "    for i in range(len(Features)):\n",
    "        Xdata_new = np.delete(Xdata, i,1)\n",
    "\n",
    "        # Calculate class weights\n",
    "        class_weights = set_weights(Ydata)\n",
    "        print(\"Class weights = \", class_weights)\n",
    "\n",
    "        # try different folds for each subset -> box plots\n",
    "        for folds in foldTypes:\n",
    "\n",
    "            # calculate outer CV for different binary classifiers\n",
    "            resList=[]\n",
    "            myACC = Pipeline_OuterCV2(Xdata_new, Ydata, label = OutVar, class_weights = class_weights, folds = folds, seed = seed)\n",
    "            print(myACC)\n",
    "            resList.append(float(myACC[0]))\n",
    "            resList.append(float(myACC[0])-OrigAUC[k]) # add feature name to ACC\n",
    "            resList.append(Features[i]) # add feature name to ACC\n",
    "            resList.append(OutVar) # add file tag\n",
    "        \n",
    "        \n",
    "        # add each result to a summary dataframe\n",
    "        all_results.append(resList)\n",
    "    k=k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(all_results,columns=['New ACC', 'Diff with Pool ACC', 'Removed Feature', 'Dataset'])\n",
    "df_results.sort_values(by=['Dataset','Diff with Pool ACC'], inplace=True)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resFile = './results2_LOOCV/'+'FeatImpbyRemoval-LOOCV_SVMlinear_ACC.csv'\n",
    "df_results.to_csv(resFile, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hf with ML!\n",
    "\n",
    "@muntisa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
