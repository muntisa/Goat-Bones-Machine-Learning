{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines for classifiers using AUC\n",
    "\n",
    "For each dataset, classifier and folds:\n",
    "- Robust scaling\n",
    "- 2, 3, 5, 10-fold outer CV\n",
    "- AUC as score\n",
    "\n",
    "We will use folders *datasets2* and *results_AUC*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, StratifiedKFold, LeaveOneOut\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, roc_auc_score,f1_score, recall_score, precision_score\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LassoCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.feature_selection import RFECV, VarianceThreshold, SelectKBest, chi2\n",
    "from sklearn.feature_selection import SelectFromModel, SelectPercentile, f_classif\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ./datasets2/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ./results_AUC/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of files in datasets2 = all datasets\n",
    "dsList = os.listdir('./datasets2')\n",
    "print('--> Found', len(dsList), 'dataset files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list with all output variable names \n",
    "outVars = []\n",
    "for eachdsFile in dsList:\n",
    "    outVars.append( (eachdsFile[:-4])[3:] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define script parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define list of folds\n",
    "foldTypes = [2,3,5,10]\n",
    "\n",
    "# define a label for output files\n",
    "targetName = '_AUC'\n",
    "\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  set_weights(y_data, option='balanced'):\n",
    "    \"\"\"Estimate class weights for umbalanced dataset\n",
    "       If ‘balanced’, class weights will be given by n_samples / (n_classes * np.bincount(y)). \n",
    "       If a dictionary is given, keys are classes and values are corresponding class weights. \n",
    "       If None is given, the class weights will be uniform \"\"\"\n",
    "    cw = class_weight.compute_class_weight(option, np.unique(y_data), y_data)\n",
    "    w = {i:j for i,j in zip(np.unique(y_data), cw)}\n",
    "    return w "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataFromDataset(sFile, OutVar):\n",
    "    # read details file\n",
    "    print('\\n-> Read dataset', sFile)\n",
    "    df = pd.read_csv(sFile)\n",
    "    #df = feather.read_dataframe(sFile)\n",
    "    print('Shape', df.shape)\n",
    "    # print(list(df.columns))\n",
    "    \n",
    "    # select X and Y\n",
    "    ds_y = df[OutVar]\n",
    "    ds_X = df.drop(OutVar,axis = 1)\n",
    "    Xdata = ds_X.values # get values of features\n",
    "    Ydata = ds_y.values # get output values\n",
    "\n",
    "    print('Shape X data:', Xdata.shape)\n",
    "    print('Shape Y data:',Ydata.shape)\n",
    "    \n",
    "    # return data for X and Y, feature names as list\n",
    "    return (Xdata, Ydata, list(ds_X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pipeline_OuterCV(Xdata, Ydata, label = 'my', class_weights = {0: 1, 1: 1}, folds = 3, seed = 42):\n",
    "    # inputs:\n",
    "    # data for X, Y; a label about data, number of folds, seeed\n",
    "    # default: 3-fold CV, 1:1 class weights (ballanced dataset)\n",
    "    \n",
    "    # define classifiers\n",
    "    names = ['KNN', 'SVM linear', 'SVM', 'LR', 'DT', 'RF', 'XGB']\n",
    "    classifiers = [KNeighborsClassifier(3),\n",
    "                   SVC(kernel=\"linear\",random_state=seed,gamma='scale'),\n",
    "                   SVC(kernel = 'rbf', random_state=seed,gamma='auto'),\n",
    "                   LogisticRegression(solver='lbfgs',random_state=seed),\n",
    "                   DecisionTreeClassifier(random_state = seed),\n",
    "                   RandomForestClassifier(n_estimators=50,n_jobs=-1,random_state=seed),\n",
    "                   XGBClassifier(n_jobs=-1,seed=seed)\n",
    "                  ]\n",
    "    # results dataframe: each column for a classifier\n",
    "    df_res = pd.DataFrame(columns=names)\n",
    "\n",
    "    # build each classifier\n",
    "    print('* Building scaling+feature selection+outer '+str(folds)+'-fold CV for '+str(len(names))+' classifiers:', str(names))\n",
    "    total = time.time()\n",
    "    \n",
    "    # define a fold-CV for all the classifier\n",
    "    outer_cv = StratifiedKFold(n_splits=folds,shuffle=True,random_state=seed)\n",
    "    \n",
    "    for name, clf in zip(names, classifiers):\n",
    "        start = time.time()\n",
    "        \n",
    "        # create pipeline: scaler + classifier\n",
    "        estimators = []\n",
    "        \n",
    "        # SCALER\n",
    "        # MinMaxScaler(), StandardScaler(), RobustScaler(),\n",
    "        estimators.append(('Scaler', RobustScaler() ))\n",
    "        \n",
    "        # add Classifier\n",
    "        estimators.append(('Classifier', clf)) \n",
    "        \n",
    "        # create pipeline\n",
    "        model = Pipeline(estimators)\n",
    "        \n",
    "        # evaluate pipeline\n",
    "        scores = cross_val_score(model, Xdata, Ydata, cv=outer_cv, scoring='roc_auc', n_jobs=-1)\n",
    "        df_res[name] = scores\n",
    "        print('%s, MeanScore=%0.2f, Time:%0.1f mins' % (name, scores.mean(), (time.time() - start)/60))\n",
    "        \n",
    "    # save results for each ML and dataset\n",
    "    resFile = './results_AUC/'+str(label)+str(targetName)+'_Outer-'+str(folds)+'-foldCV.csv'\n",
    "    df_res.to_csv(resFile, index=False)\n",
    "    print('* Scores saved', resFile)  \n",
    "    print('Total time:', (time.time() - total)/60, ' mins')             \n",
    "    \n",
    "    # return AUC scores for all classifiers as dataframe (each column a classifier)\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each subset file\n",
    "df_results = None # all results \n",
    "\n",
    "for OutVar in outVars:\n",
    "    sFile = './datasets2/ds.'+str(OutVar)+'.csv'\n",
    "\n",
    "    # get data from file\n",
    "    Xdata, Ydata, Features = getDataFromDataset(sFile,OutVar)\n",
    "\n",
    "    # Calculate class weights\n",
    "    class_weights = set_weights(Ydata)\n",
    "    print(\"Class weights = \", class_weights)\n",
    "        \n",
    "    # try different folds for each subset -> box plots\n",
    "    for folds in foldTypes:\n",
    "        \n",
    "        # calculate outer CV for different binary classifiers\n",
    "        df_fold = Pipeline_OuterCV(Xdata, Ydata, label = OutVar, class_weights = class_weights, folds = folds, seed = seed)\n",
    "        df_fold['Dataset'] = OutVar\n",
    "        df_fold['folds'] = folds\n",
    "        \n",
    "        # add each result to a summary dataframe\n",
    "        df_results = pd.concat([df_results,df_fold])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resFile = './results_AUC/'+'ML_Outer-n-foldCV.csv'\n",
    "df_results.to_csv(resFile, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_means =df_results.groupby(['Dataset','folds'], as_index = False).mean()[['Dataset', 'folds','KNN', 'SVM linear', 'SVM', 'LR', 'DT', 'RF', 'XGB']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resFile_means = './results_AUC/'+'ML_Outer-n-foldCV_means.csv'\n",
    "df_means.to_csv(resFile_means, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best ML results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the maximum value rows for all MLs\n",
    "bestMLs = df_means[['KNN', 'SVM linear', 'SVM', 'LR', 'DT', 'RF', 'XGB']].idxmax()\n",
    "print(bestMLs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the best score by ML method\n",
    "for ML in ['KNN', 'SVM linear', 'SVM', 'LR', 'DT', 'RF', 'XGB']:\n",
    "    print(ML, '\\t', list(df_means.iloc[df_means[ML].idxmax()][['Dataset', 'folds', ML]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column with the original output name (get first 2 characters from Dataset column)\n",
    "getOutOrig = []\n",
    "for each in df_means['Dataset']:\n",
    "    getOutOrig.append(each[:2])\n",
    "df_means['Output'] = getOutOrig\n",
    "df_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resFile_means2 = './results_AUC/'+'ML_Outer-n-foldCV_means2.csv'\n",
    "df_means.to_csv(resFile_means2, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the best ML for each type of output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for outName in list(set(df_means['Output'])):\n",
    "    print('*********************')\n",
    "    print('OUTPUT =', outName)\n",
    "    df_sel = df_means[df_means['Output'] == outName].copy()\n",
    "    for ML in ['KNN', 'SVM linear', 'SVM', 'LR', 'DT', 'RF', 'XGB']:\n",
    "        print(ML, '\\t', list(df_sel.loc[df_sel[ML].idxmax(),:][['Dataset', 'folds', ML]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sel.loc[df_sel[ML].idxmax(),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the best ML for each type of output for 10-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10fold = df_means[df_means['folds']==10].copy()\n",
    "df_10fold.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for outName in list(set(df_10fold['Output'])):\n",
    "    print('*********************')\n",
    "    print('OUTPUT =', outName)\n",
    "    \n",
    "    df_sel = df_10fold[df_10fold['Output'] == outName].copy()\n",
    "    print('MAX =',df_sel[['KNN', 'SVM linear', 'SVM', 'LR', 'DT', 'RF', 'XGB']].max().max())\n",
    "    \n",
    "    for ML in ['KNN', 'SVM linear', 'SVM', 'LR', 'DT', 'RF', 'XGB']:\n",
    "        print(ML, '\\t', list(df_sel.loc[df_sel[ML].idxmax(),:][['Dataset', 'folds', ML]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5fold = df_means[df_means['folds']==5].copy()\n",
    "df_5fold.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for outName in list(set(df_5fold['Output'])):\n",
    "    print('*********************')\n",
    "    print('OUTPUT =', outName)\n",
    "    \n",
    "    df_sel = df_5fold[df_5fold['Output'] == outName].copy()\n",
    "    print('MAX =',df_sel[['KNN', 'SVM linear', 'SVM', 'LR', 'DT', 'RF', 'XGB']].max().max())\n",
    "    \n",
    "    for ML in ['KNN', 'SVM linear', 'SVM', 'LR', 'DT', 'RF', 'XGB']:\n",
    "        print(ML, '\\t', list(df_sel.loc[df_sel[ML].idxmax(),:][['Dataset', 'folds', ML]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('5-fold CV')\n",
    "for outName in list(set(df_5fold['Output'])):\n",
    "    df_sel = df_5fold[df_5fold['Output'] == outName].copy()\n",
    "    print(outName,df_sel[['KNN', 'SVM linear', 'SVM', 'LR', 'DT', 'RF', 'XGB']].max().max())\n",
    "    \n",
    "print('10-fold CV')\n",
    "for outName in list(set(df_10fold['Output'])):\n",
    "    df_sel = df_10fold[df_10fold['Output'] == outName].copy()\n",
    "    print(outName,df_sel[['KNN', 'SVM linear', 'SVM', 'LR', 'DT', 'RF', 'XGB']].max().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**: using AUC as score, we are able to obtain classification models with AUC > 0.70 for the majority of outputs and even AUC > 0.85!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
